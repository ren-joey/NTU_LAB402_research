{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 18:25:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:16:00.0 Off |                  Off |\n",
      "|  0%   30C    P8              11W / 450W |  14258MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check GPU type.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python package installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchio in /home/jovyan/.local/lib/python3.10/site-packages (0.19.6)\n",
      "Requirement already satisfied: Deprecated in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (1.2.14)\n",
      "Requirement already satisfied: SimpleITK!=2.0.*,!=2.1.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (2.3.1)\n",
      "Requirement already satisfied: humanize in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (4.9.0)\n",
      "Requirement already satisfied: nibabel in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (1.26.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torchio) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.1)\n",
      "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=1.1->torchio) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.1.0+e621604)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jovyan/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1->torchio) (12.3.101)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/jovyan/.local/lib/python3.10/site-packages (from Deprecated->torchio) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (23.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.6)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/jovyan/.local/lib/python3.10/site-packages (from typer[all]->torchio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from typer[all]->torchio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/jovyan/.local/lib/python3.10/site-packages (from typer[all]->torchio) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup\n",
      "  Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to /tmp/pip-req-build-d0p3l2n6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup /tmp/pip-req-build-d0p3l2n6\n",
      "  Resolved https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to commit 12d03c07553aedd3d9e9155e2b3e31ce8c64081a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torchio\n",
    "!pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# System packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import splitext, isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchio as tio\n",
    "\n",
    "# Visualization packages\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loggin file name: ./log_1710181517.142172.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "timestamp = current_datetime.timestamp()\n",
    "filename = './log_{}.log'.format(timestamp)\n",
    "print(f'loggin file name: {filename}')\n",
    "logging.basicConfig(filename=filename, level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    seed = 77777777\n",
    "    \n",
    "    # Data\n",
    "    img_size = (512, 512)\n",
    "    in_channels = 1\n",
    "    \n",
    "    # 4 classes\n",
    "    n_classes = 4\n",
    "    train_img_path = './rtmets-sarcopenia/muscle_group_segment/train/xdata'\n",
    "    train_mask_path = './rtmets-sarcopenia/muscle_group_segment/train/ydata'\n",
    "    valid_img_path = './rtmets-sarcopenia/muscle_group_segment/validation/xdata'\n",
    "    valid_mask_path = './rtmets-sarcopenia/muscle_group_segment/validation/ydata'\n",
    "    all_img_path = './rtmets-sarcopenia/muscle_group_segment/all'\n",
    "    img_4c_path = './rtmets-sarcopenia/4_channels_sm'\n",
    "    \n",
    "    # Clinical Data\n",
    "    train_data_path = './rtmets-sarcopenia/RT_spine_NESMS_info/train.csv'\n",
    "    valid_data_path = './rtmets-sarcopenia/RT_spine_NESMS_info/valid.csv'\n",
    "    all_data_path = './rtmets-sarcopenia/RT_spine_NESMS_info/all.csv'\n",
    "    train_val_test_list_path = './rtmets-sarcopenia/train_val_test_split.csv'\n",
    "    pred_days = 365 # 42days, 90days, 365days\n",
    "    y_data_reverse = True\n",
    "    use_damper = True\n",
    "    \n",
    "    # Data Folding\n",
    "    cross_valid = 1\n",
    "    data_sampling = 'under-sampling' # 'no-sampling' | 'over-sampling' | 'under-sampling'\n",
    "\n",
    "    val_percent: float = 0.1\n",
    "    img_scale: float = 1.0\n",
    "    \n",
    "    # Transforms\n",
    "    scale = (0.7, 1.0)\n",
    "    \n",
    "    # Model args\n",
    "    bilinear = False\n",
    "    save_checkpoint: bool = True\n",
    "    amp: bool = False\n",
    "    checkpoint = './rtmets-sarcopenia/checkpoints/checkpoint_epoch48_0008.pth'\n",
    "    model_dir = './model/under-sampling'\n",
    "    \n",
    "    # Hyper parameters\n",
    "    patience: int = math.inf\n",
    "    epochs: int = 100\n",
    "    batch_size: int = 8\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-1\n",
    "    momentum: float = 0.999\n",
    "    gradient_clipping: float = 1.0\n",
    "    optimizer = 'AdamW'\n",
    "    patience = 5\n",
    "    dropout = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_setting(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "def save_model(model_dir, model, args, epoch=None, k=None):\n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_dir = model_dir.joinpath('{}d_fold{}_checkpoint_epoch{}.pth'.format(cfg.pred_days, k, epoch))\n",
    "\n",
    "    torch.save({\n",
    "        'epochs': args.epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'batch_size': args.batch_size,\n",
    "        'lr': args.lr,\n",
    "        'weight_decay': args.weight_decay,\n",
    "        'optimizer': args.optimizer,\n",
    "        'patience': args.patience,\n",
    "    }, model_dir)\n",
    "\n",
    "def get_label_weights(args, k):\n",
    "#     weights = [3, 1]\n",
    "    weights = [1, 1]\n",
    "    logging.warning('weights = {}'.format(weights))\n",
    "    weights = torch.tensor(weights.copy(), dtype=torch.float32)\n",
    "    weights = weights.to(device)\n",
    "    return weights\n",
    "\n",
    "# all_scorer = sklearn.metrics.get_scorer_names()\n",
    "# print(all_scorer)\n",
    "\n",
    "def evaluate_preds(y_test, preds, _preds):\n",
    "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, _preds).ravel()\n",
    "#     print(f'tn: {tn}, fp: {fp}, fn: {fn}, tp: {tp}')\n",
    "\n",
    "    acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "    # acc = sklearn.metrics.accuracy_score(y_test, _preds)\n",
    "\n",
    "    tpr = tp/(tp+fn) # Recall, tpr, sensitivity\n",
    "    # sensitivity = sklearn.metrics.recall_score(y_test, _preds)\n",
    "\n",
    "    tnr = tn/(tn+fp) # tnr, specificity\n",
    "    \n",
    "    ppv = tp/(tp+fp) # Precision & ppv\n",
    "    # precision = sklearn.metrics.precision_score(y_test, _preds)\n",
    "\n",
    "    npv = tn/(tn+fn)\n",
    "    \n",
    "#     try:\n",
    "#         f1 = ((2*ppv*tpr)/(ppv+tpr))\n",
    "#     except:\n",
    "#         f1 = 0\n",
    "    # f1 = sklearn.metrics.f1_score(y_test, _preds)\n",
    "\n",
    "    y_test = 1 - np.array(y_test)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, preds)\n",
    "    auc = 1 - auc if auc < 0.5 else auc\n",
    "    \n",
    "#     fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, preds)\n",
    "#     roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "#     display = sklearn.metrics.RocCurveDisplay(\n",
    "#         fpr=fpr,\n",
    "#         tpr=tpr,\n",
    "#         roc_auc=roc_auc\n",
    "#     )\n",
    "#     display.plot()\n",
    "#     plt.show()\n",
    "\n",
    "    logging.info(f'acc: {acc:.4}, tpr: {tpr:.4}, tnr: {tnr:.4}, ppv: {ppv:.4}, npv: {npv:.4}, auc: {auc:.4}')\n",
    "\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparing(data_path):\n",
    "    res = pd.read_csv(data_path)\n",
    "    data = res.values\n",
    "    header = res.columns.to_numpy()\n",
    "    \n",
    "    x_data, y_42d_data, y_90d_data, y_365d_data = data[:, :-3], data[:, -3], data[:, -2], data[:, -1]\n",
    "    \n",
    "    return x_data, y_42d_data, y_90d_data, y_365d_data, header\n",
    "\n",
    "def distribution_map_preparing(train_val_test_list_path):\n",
    "    test = pd.read_csv(train_val_test_list_path, header=None)\n",
    "    data = test.values.tolist()\n",
    "    new_data = []\n",
    "    for each in data:\n",
    "        each = [i for i in each if str(i) != 'nan']\n",
    "        each = each[1:]\n",
    "        new_data.append(each)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "##### Dataset #####\n",
    "class L3_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 images_path=None, clinical_data_path=None, train_val_test_list_path=None,\n",
    "                 mode=None, k=0, predict_mode=False, days=42, reverse=False, sampling='over-sampling'):\n",
    "        # finish no-sampling\n",
    "        assert sampling in ('over-sampling', 'under-sampling', 'no-sampling')\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        self.clinical_data_path = clinical_data_path\n",
    "        self.mode = mode\n",
    "        self.predict_mode = predict_mode\n",
    "        split_map = distribution_map_preparing(train_val_test_list_path)\n",
    "        \n",
    "        x_data, y_42d_data, y_90d_data, y_365d_data, self.header = data_preparing(self.clinical_data_path)\n",
    "        self.x_data = x_data\n",
    "\n",
    "        if days == 42:\n",
    "            self.y_data = y_42d_data\n",
    "            base_idx = 0\n",
    "        elif days == 90:\n",
    "            self.y_data = y_90d_data\n",
    "            base_idx = 15\n",
    "        elif days == 365:\n",
    "            self.y_data = y_365d_data\n",
    "            base_idx = 30\n",
    "        else:\n",
    "            raise\n",
    "        \n",
    "        if sampling == 'under-sampling':\n",
    "            base_idx += 45\n",
    "        \n",
    "        base_idx += k * 3\n",
    "        if mode == 'train':\n",
    "            self.split_map = split_map[base_idx] + split_map[base_idx + 1]\n",
    "        elif mode == 'val':\n",
    "            self.split_map = split_map[base_idx + 2]\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "        if reverse:\n",
    "            self.y_data = 1 - self.y_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.split_map)\n",
    "\n",
    "    def __getitem__(self, origin_idx):\n",
    "        idx = int(self.split_map[origin_idx] - 1)\n",
    "\n",
    "        img_path = Path(self.images_path, f'{idx + 1}.npy')\n",
    "#         mask_path = Path(self.images_path, 'ydata', f'{idx+1}.png')\n",
    "        img_name = img_path.stem\n",
    "\n",
    "        # label\n",
    "        label = self.y_data[idx]\n",
    "        label = int(label)\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        # Image\n",
    "        c4_img = np.load(img_path)\n",
    "        c4_img = c4_img.astype(np.float32)\n",
    "#         c4_img = np.zeros((512, 512, 4), dtype=np.float32)\n",
    "#         ct_img = np.array(Image.open(img_path))\n",
    "#         mask_img = np.array(Image.open(mask_path))\n",
    "#         for (y, rows) in enumerate(ct_img):\n",
    "#             for (x, p) in enumerate(rows):\n",
    "#                 [r, g, b] = mask_img[y][x]\n",
    "#                 c4_img[y][x] = [r, g, b, p]\n",
    "        c4_img = c4_img[:, :, :, np.newaxis].transpose((2, 3, 0, 1))\n",
    "\n",
    "        # clinical features\n",
    "        clinical_values = torch.tensor(self.x_data[idx], dtype=torch.float32)\n",
    "\n",
    "        return img_name, c4_img, clinical_values, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, size_average=True, weights=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.size_average = size_average\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        pt = F.softmax(input, dim=1)\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        weights = self.weights.index_select(0, target) # nice\n",
    "        target = target.view(-1, 1) # 1維 -> 2維\n",
    "\n",
    "        pt = pt.gather(1, target)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        pt = pt.view(-1)\n",
    "        logpt = logpt.view(-1)\n",
    "\n",
    "        loss = -1 * weights * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class GCT(nn.Module):\n",
    "    def __init__(self, channel, epsilon=1e-5, mode='l2', after_relu=False):\n",
    "        super(GCT, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.after_relu = after_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'l2':\n",
    "            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n",
    "            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n",
    "        else:\n",
    "            logging.WARNING('Unknown mode!')\n",
    "            sys.exit()\n",
    "\n",
    "        # gate = 1. + torch.tanh(embedding * norm + self.beta)\n",
    "        gate = 1. + torch.sigmoid(embedding * norm + self.beta)\n",
    "\n",
    "        return x * gate\n",
    "\n",
    "class BAM(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction=2, dilation_val=4, num_layers=1):\n",
    "        super(BAM, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.channel_att = nn.Sequential(\n",
    "            nn.Linear(gate_channel, gate_channel // reduction),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channel // reduction, gate_channel)\n",
    "        )\n",
    "\n",
    "        # input (_, _, D, H, W) -> output (_, _, D, H, W) for any Conv3D\n",
    "        self.spatial_att = nn.Sequential(\n",
    "            nn.Conv3d(gate_channel, gate_channel // reduction, kernel_size=1),\n",
    "            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(gate_channel // reduction, gate_channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n",
    "            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(gate_channel // reduction, gate_channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n",
    "            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(gate_channel//reduction, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        # compute channel attention\n",
    "        channel_part = self.avg_pool(x).view(b, c)\n",
    "        channel_part = self.channel_att(channel_part).view(b, c, 1, 1, 1).expand_as(x)\n",
    "        # compute spatial attention\n",
    "        spatial_part = self.spatial_att(x).expand_as(x)\n",
    "        # add together\n",
    "        att = 1 + F.sigmoid(channel_part + spatial_part)\n",
    "        return att * x\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction=2):\n",
    "        super().__init__()\n",
    "        # channel attention\n",
    "        self.pools = [\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.AdaptiveMaxPool3d(1)\n",
    "        ]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(gate_channel, gate_channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(gate_channel // reduction, gate_channel)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # spatial attention\n",
    "        kernel_size = 7\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(2, 1, kernel_size=kernel_size, stride=1, padding=(kernel_size-1) // 2),\n",
    "            LayerNorm(1, data_format=\"channels_first\"),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        b, c, _, _, _ = x.size()\n",
    "\n",
    "        channel_part = None\n",
    "        for pool in self.pools:\n",
    "            y = pool(x).view(b, c)\n",
    "            y = self.mlp(y)\n",
    "            channel_part = channel_part + y if channel_part is not None else y \n",
    "        channel_part = self.sigmoid(channel_part).view(b, c, 1, 1, 1)\n",
    "        x = x * channel_part.expand_as(x)\n",
    "\n",
    "        spatial_part = torch.cat( (torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1 )\n",
    "        spatial_part = self.conv(spatial_part)\n",
    "        x = x * spatial_part.expand_as(x)\n",
    "\n",
    "        return x + res\n",
    "\n",
    "class SE_GCT(nn.Module):\n",
    "    def __init__(self, channel, reduction=2, epsilon=1e-5, mode='l2', after_relu=False):\n",
    "        super().__init__()\n",
    "        # Squeeze and excitation\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "        )\n",
    "        # GCT\n",
    "        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.after_relu = after_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # compute SE attention\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        se_gate = self.fc(y).view(b, c, 1, 1, 1).expand_as(x)\n",
    "\n",
    "        # compute GCT attention\n",
    "        if self.mode == 'l2':\n",
    "            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n",
    "            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n",
    "        else:\n",
    "            logging.WARNING('Unknown mode!')\n",
    "            sys.exit()\n",
    "        gct_gate = embedding * norm + self.beta\n",
    "\n",
    "        # add together\n",
    "        att = 1 + F.sigmoid(se_gate + gct_gate)\n",
    "        return att * x\n",
    "\n",
    "class BAM_GCT(nn.Module):\n",
    "    def __init__(self, channel, reduction=2, dilation_val=4, num_layers=1, epsilon=1e-5, mode='l2', after_relu=False):\n",
    "        super().__init__()\n",
    "        # Squeeze and excitation\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "        )\n",
    "        # GCT\n",
    "        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.after_relu = after_relu\n",
    "\n",
    "        # input (_, _, D, H, W) -> output (_, _, D, H, W) for any Conv3D\n",
    "        self.spatial_att = nn.Sequential(\n",
    "            nn.Conv3d(channel, channel // reduction, kernel_size=1),\n",
    "            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(channel // reduction, channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n",
    "            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(channel // reduction, channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n",
    "            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(channel//reduction, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        # compute channel attention\n",
    "\n",
    "        # compute SE attention\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1).expand_as(x)\n",
    "\n",
    "        # compute GCT attention\n",
    "        if self.mode == 'l2':\n",
    "            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n",
    "            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n",
    "        else:\n",
    "            logging.WARNING('Unknown mode!')\n",
    "            sys.exit()\n",
    "        gate = embedding * norm + self.beta\n",
    "\n",
    "        # add together\n",
    "        channel_part = y + gate\n",
    "\n",
    "        # compute spatial attention\n",
    "        spatial_part = self.spatial_att(x).expand_as(x)\n",
    "        # add together\n",
    "        att = 1 + F.sigmoid(channel_part + spatial_part)\n",
    "        return att * x\n",
    "\n",
    "class CBAM_GCT(nn.Module):\n",
    "    def __init__(self, channel, reduction=2, epsilon=1e-5, mode='l2', after_relu=False):\n",
    "        super().__init__()\n",
    "        # channel attention\n",
    "        self.pools = [\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.AdaptiveMaxPool3d(1)\n",
    "        ]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # GCT\n",
    "        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n",
    "        self.epsilon = epsilon\n",
    "        self.mode = mode\n",
    "        self.after_relu = after_relu\n",
    "\n",
    "        # spatial attention\n",
    "        kernel_size = 7\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(2, 1, kernel_size=kernel_size, stride=1, padding=(kernel_size-1) // 2),\n",
    "            LayerNorm(1, data_format=\"channels_first\"),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        b, c, _, _, _ = x.size()\n",
    "\n",
    "        channel_part = None\n",
    "        for pool in self.pools:\n",
    "            y = pool(x).view(b, c)\n",
    "            y = self.mlp(y)\n",
    "            channel_part = channel_part + y if channel_part is not None else y \n",
    "        channel_part = channel_part.view(b, c, 1, 1, 1)\n",
    "\n",
    "        # compute GCT attention\n",
    "        if self.mode == 'l2':\n",
    "            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n",
    "            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n",
    "        else:\n",
    "            logging.WARNING('Unknown mode!')\n",
    "            sys.exit()\n",
    "        gate = embedding * norm + self.beta\n",
    "\n",
    "        # add together\n",
    "        channel_part = channel_part + gate\n",
    "        channel_part = F.sigmoid(channel_part)\n",
    "        x = x * channel_part.expand_as(x)\n",
    "\n",
    "        spatial_part = torch.cat( (torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1 )\n",
    "        spatial_part = self.conv(spatial_part)\n",
    "        x = x * spatial_part.expand_as(x)\n",
    "\n",
    "        return x + res\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRN(nn.Module):\n",
    "    # gamma, beta: learnable affine transform parameters\n",
    "    # X: input of shape (N, D, H, W, C)\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.zeros((dim)))\n",
    "        self.beta = nn.Parameter(torch.zeros((dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        gx = torch.norm(x, p=2, dim=(1, 2, 3), keepdim=True)\n",
    "        nx = gx / (gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
    "        return self.gamma * (x * nx) + self.beta + x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, D, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, depth_number: int, pos_in_depth: int, drop_path=0.5, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv3d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.depth_number = depth_number\n",
    "        self.pos_in_depth = pos_in_depth\n",
    "        self.se_gct = SE_GCT(channel=dim, reduction=2) # TODO:\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 4, 1) # (N, C, D, H, W) -> (N, D, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 4, 1, 2, 3) # (N, D, H, W, C) -> (N, C, D, H, W)\n",
    "\n",
    "        if self.pos_in_depth == 3:\n",
    "            x = self.se_gct(x)\n",
    "\n",
    "        x = input + x\n",
    "        return x\n",
    "\n",
    "class ConvNeXt(nn.Module):\n",
    "    r\"\"\" ConvNeXt\n",
    "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, in_chans=4, num_classes=2, \n",
    "            depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n",
    "            layer_scale_init_value=1e-6, head_init_scale=1., len_of_clinical_features=71,\n",
    "            use_damper=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        # depths=[1, 1, 3, 1], dims=[8, 16, 32, 64]\n",
    "        self.use_damper = use_damper\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv3d(in_chans, dims[0], kernel_size=(1, 4, 4), stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                nn.Conv3d(dims[i], dims[i+1], kernel_size=(1, 2, 2), stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], layer_scale_init_value=layer_scale_init_value, depth_number=i+1, pos_in_depth=j+1) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        \n",
    "        # voi size\n",
    "        self.v_fc1 = nn.Linear(len_of_clinical_features, 16)\n",
    "        self.v_fc2 = nn.Linear(16, dims[-1])\n",
    "        self.v_fc3 = nn.Linear(dims[-1], dims[-1])\n",
    "        \n",
    "        # final\n",
    "        len_of_features = dims[-1] + len_of_clinical_features\n",
    "        self.fc1 = nn.Linear(len_of_features, len_of_features // 2) # 214 = dim[-1] + dim(clinical_info) which is 150\n",
    "        self.fc2 = nn.Linear(len_of_features // 2, len_of_features // 4)\n",
    "        self.fc3 = nn.Linear(len_of_features // 4, 2)\n",
    "        self.bn1 = nn.BatchNorm1d(len_of_features // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(len_of_features // 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv3d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02) # 正態分佈\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-3, -2, -1])) # global average pooling, (N, C, D, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x, clinical_info):\n",
    "        x_feature = self.forward_features(x)\n",
    "        \n",
    "        if self.use_damper:\n",
    "            voi_feature = self.v_fc1(clinical_info)\n",
    "            voi_feature = self.v_fc2(voi_feature)\n",
    "            voi_feature = self.v_fc3(voi_feature)\n",
    "\n",
    "            b, n = x_feature.size()\n",
    "            _sum = (x_feature * voi_feature).sum(dim=(-1))\n",
    "            x = x_feature - (_sum / n).view(b, 1).expand_as(x_feature)\n",
    "\n",
    "        x = torch.cat((x_feature, clinical_info), 1)\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def convnext_tiny(pretrained=False, in_22k=False, **kwargs):\n",
    "    # original dims = [96, 192, 384, 768]\n",
    "    # best dims = [8, 16, 32, 64]\n",
    "    model = ConvNeXt(depths=[1, 1, 3, 1], dims=[8, 16, 32, 64], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, k: int, device, model, optimizer, criterion, scheduler, trainloader, valloader, seed):\n",
    "    \n",
    "    the_last_loss = 100\n",
    "    trigger_times = 0\n",
    "\n",
    "    the_best_loss = 0\n",
    "#     the_best_accuracy = 0\n",
    "    the_best_auc = 0\n",
    "    the_best_acc_auc_mul = 0\n",
    "\n",
    "    save_path = Path(args.model_dir)\n",
    "    save_tradoff_path = Path(args.model_dir, 'tradoff')\n",
    "    save_auc_path = Path(args.model_dir, 'auc')\n",
    "    save_acc_auc_mul_path = Path(args.model_dir, 'acc_auc_mul')\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "#         epoch_loss, epoch_accuracy = 0, 0\n",
    "        epoch_loss = 0\n",
    "        train_label, train_pred = [], []\n",
    "        model.train()\n",
    "        for i, (_, img, clinical_info, label) in enumerate(trainloader):\n",
    "            img, clinical_info, label = img.to(device), clinical_info.to(device), label.to(device)\n",
    "\n",
    "            output = model(img, clinical_info)  #[bs, 2]\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # _, pred = torch.max(output, dim=1)\n",
    "            pred = torch.where(output[:, 0] > 0.475, 0, 1)\n",
    "            loss = criterion(output, label)  #focal\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.detach().cpu().item()\n",
    "#             epoch_accuracy += torch.sum(pred == label)\n",
    "\n",
    "            train_label += label.detach().cpu().numpy().tolist()\n",
    "            train_pred += pred.detach().cpu().numpy().tolist()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = epoch_loss / (len(trainloader) * args.batch_size)\n",
    "#         epoch_accuracy = epoch_accuracy.float() / (len(trainloader) * args.batch_size)\n",
    "#         tp, fn, fp, tn = confusion_matrix(train_label, train_pred).ravel()\n",
    "#         tnr, fpr, fnr, tpr = tn/(fp+tn), fp/(fp+tn), fn/(tp+fn), tp/(tp+fn)\n",
    "#         print(f'[{k}/{5}][{epoch}/{args.epochs}] loss: {epoch_loss:.8}, accuracy: {epoch_accuracy:.2}, tnr = {tnr:.2}, tpr = {tpr:.2}')\n",
    "        print(f'[{k+1}/{5}][{epoch}/{args.epochs}] loss: {epoch_loss:.8}')\n",
    "        logging.info(f'[{k+1}/{5}][{epoch}/{args.epochs}] loss: {epoch_loss:.8}')\n",
    "\n",
    "        # Early stopping\n",
    "        the_current_loss, the_current_accuracy, the_current_auc = validation(device, model, criterion, valloader)\n",
    "#         print(f'[validation] The current loss: {the_current_loss:.8}, accuracy: {the_current_accuracy:.2}')\n",
    "        acc_auc_mul = the_current_accuracy * the_current_auc\n",
    "        logging.info(f'[validation] The current loss: {the_current_loss:.8}, acc*auc: {acc_auc_mul:.4}')\n",
    "\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            logging.info('trigger times: {}'.format(trigger_times))\n",
    "\n",
    "            if trigger_times >= args.patience:\n",
    "                logging.warning(f'Early stopping!\\nEpoch = {epoch}')\n",
    "                return\n",
    "        else:\n",
    "#             print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "#         if epoch == 0 or the_best_loss >= the_current_loss:\n",
    "#             print(f'Recording best model. ({save_path})')\n",
    "#             save_model(save_path, model, args, epoch, k)\n",
    "#             the_best_loss = the_current_loss\n",
    "\n",
    "#         if the_current_accuracy > the_best_accuracy:\n",
    "#             print(f'Recording best tradeoff model. ({save_tradoff_path})')\n",
    "#             save_model(save_tradoff_path, model, args, epoch, k)\n",
    "#             the_best_accuracy = the_current_accuracy\n",
    "        \n",
    "        if the_current_auc > the_best_auc:\n",
    "            logging.info(f'Recording best auc model. ({save_auc_path})')\n",
    "            save_model(save_auc_path, model, args, epoch, k)\n",
    "            the_best_auc = the_current_auc\n",
    "        \n",
    "        if acc_auc_mul > the_best_acc_auc_mul:\n",
    "            logging.critical(f'Recording best acc*auc model. ({save_acc_auc_mul_path})')\n",
    "            save_model(save_acc_auc_mul_path, model, args, epoch, k)\n",
    "            the_best_acc_auc_mul = acc_auc_mul\n",
    "\n",
    "        the_last_loss = the_current_loss\n",
    "\n",
    "    logging.info(f'stopping! Epoch = {args.epochs}')\n",
    "    return \n",
    "\n",
    "def validation(device, model, criterion, valloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "#     val_accuracy = 0\n",
    "    val_label, val_pred, val_c0 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, img, clinical_info, label in valloader:\n",
    "            img, clinical_info, label = img.to(device), clinical_info.to(device), label.to(device)\n",
    "            output = model(img, clinical_info)  #[bs, 2]\n",
    "            \n",
    "            # _, pred = torch.max(output, dim=1)\n",
    "            c0 = output[:, 0]\n",
    "            pred = torch.where(output[:, 0] > 0.475, 0, 1)\n",
    "            loss = criterion(output, label)  #focal\n",
    "            val_loss += loss.detach().cpu().item()\n",
    "#             val_accuracy += torch.sum(pred == label)\n",
    "\n",
    "            val_label += label.detach().cpu().numpy().tolist()\n",
    "            val_pred += pred.detach().cpu().numpy().tolist()\n",
    "            val_c0 += c0.detach().cpu().numpy().tolist()\n",
    "\n",
    "    acc, auc = evaluate_preds(val_label, val_c0, val_pred)\n",
    "\n",
    "    val_loss = val_loss / len(valloader)\n",
    "#     val_accuracy = val_accuracy.float() / len(valloader)\n",
    "            \n",
    "    return val_loss, acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5][0/100] loss: 0.021929885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1320852/77998675.py:49: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ppv = tp/(tp+fp) # Precision & ppv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5][1/100] loss: 0.02193206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1320852/77998675.py:49: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ppv = tp/(tp+fp) # Precision & ppv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5][2/100] loss: 0.021854491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1320852/77998675.py:49: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ppv = tp/(tp+fp) # Precision & ppv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5][3/100] loss: 0.021715436\n",
      "[5/5][4/100] loss: 0.02157149\n",
      "[5/5][5/100] loss: 0.021488281\n",
      "[5/5][6/100] loss: 0.021397201\n",
      "[5/5][7/100] loss: 0.02151585\n",
      "[5/5][8/100] loss: 0.021224004\n",
      "[5/5][9/100] loss: 0.02123809\n",
      "[5/5][10/100] loss: 0.021196503\n",
      "[5/5][11/100] loss: 0.021246462\n",
      "[5/5][12/100] loss: 0.021070482\n",
      "[5/5][13/100] loss: 0.020863624\n",
      "[5/5][14/100] loss: 0.020896857\n",
      "[5/5][15/100] loss: 0.020743324\n",
      "[5/5][16/100] loss: 0.020903559\n",
      "[5/5][17/100] loss: 0.02074339\n",
      "[5/5][18/100] loss: 0.020423974\n",
      "[5/5][19/100] loss: 0.02059706\n",
      "[5/5][20/100] loss: 0.02031956\n",
      "[5/5][21/100] loss: 0.020526505\n",
      "[5/5][22/100] loss: 0.020113529\n",
      "[5/5][23/100] loss: 0.019965697\n",
      "[5/5][24/100] loss: 0.020136396\n",
      "[5/5][25/100] loss: 0.020163702\n",
      "[5/5][26/100] loss: 0.020059818\n",
      "[5/5][27/100] loss: 0.020252133\n",
      "[5/5][28/100] loss: 0.019940838\n",
      "[5/5][29/100] loss: 0.019889957\n",
      "[5/5][30/100] loss: 0.019938863\n",
      "[5/5][31/100] loss: 0.020193256\n",
      "[5/5][32/100] loss: 0.019544589\n",
      "[5/5][33/100] loss: 0.020215821\n",
      "[5/5][34/100] loss: 0.019713981\n",
      "[5/5][35/100] loss: 0.020050855\n",
      "[5/5][36/100] loss: 0.019719871\n",
      "[5/5][37/100] loss: 0.019543013\n",
      "[5/5][38/100] loss: 0.019425294\n",
      "[5/5][39/100] loss: 0.019185211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1320852/77998675.py:52: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  npv = tn/(tn+fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5][40/100] loss: 0.01885021\n",
      "[5/5][41/100] loss: 0.018370528\n",
      "[5/5][42/100] loss: 0.018072394\n",
      "[5/5][43/100] loss: 0.018541821\n",
      "[5/5][44/100] loss: 0.018138083\n",
      "[5/5][45/100] loss: 0.017632451\n",
      "[5/5][46/100] loss: 0.017504911\n",
      "[5/5][47/100] loss: 0.017301232\n",
      "[5/5][48/100] loss: 0.016895767\n",
      "[5/5][49/100] loss: 0.01709317\n",
      "[5/5][50/100] loss: 0.017264307\n",
      "[5/5][51/100] loss: 0.017059718\n",
      "[5/5][52/100] loss: 0.016674747\n",
      "[5/5][53/100] loss: 0.016908877\n",
      "[5/5][54/100] loss: 0.016716931\n",
      "[5/5][55/100] loss: 0.016510654\n",
      "[5/5][56/100] loss: 0.017126794\n",
      "[5/5][57/100] loss: 0.017402603\n",
      "[5/5][58/100] loss: 0.016392786\n",
      "[5/5][59/100] loss: 0.016462873\n",
      "[5/5][60/100] loss: 0.016783525\n",
      "[5/5][61/100] loss: 0.016499259\n",
      "[5/5][62/100] loss: 0.016086412\n",
      "[5/5][63/100] loss: 0.015928622\n",
      "[5/5][64/100] loss: 0.015376169\n",
      "[5/5][65/100] loss: 0.015470947\n",
      "[5/5][66/100] loss: 0.014949909\n",
      "[5/5][67/100] loss: 0.014729256\n",
      "[5/5][68/100] loss: 0.014297752\n",
      "[5/5][69/100] loss: 0.014482783\n",
      "[5/5][70/100] loss: 0.013875433\n",
      "[5/5][71/100] loss: 0.014027051\n",
      "[5/5][72/100] loss: 0.014415406\n",
      "[5/5][73/100] loss: 0.013965414\n",
      "[5/5][74/100] loss: 0.013540593\n",
      "[5/5][75/100] loss: 0.013286209\n",
      "[5/5][76/100] loss: 0.013555707\n",
      "[5/5][77/100] loss: 0.013840788\n",
      "[5/5][78/100] loss: 0.014231331\n",
      "[5/5][79/100] loss: 0.013354439\n",
      "[5/5][80/100] loss: 0.01357981\n",
      "[5/5][81/100] loss: 0.013712223\n",
      "[5/5][82/100] loss: 0.013305726\n",
      "[5/5][83/100] loss: 0.013885837\n",
      "[5/5][84/100] loss: 0.014910051\n",
      "[5/5][85/100] loss: 0.014404324\n",
      "[5/5][86/100] loss: 0.013631467\n",
      "[5/5][87/100] loss: 0.013766056\n",
      "[5/5][88/100] loss: 0.013864137\n",
      "[5/5][89/100] loss: 0.012891487\n",
      "[5/5][90/100] loss: 0.012985733\n",
      "[5/5][91/100] loss: 0.012636806\n",
      "[5/5][92/100] loss: 0.012710503\n",
      "[5/5][93/100] loss: 0.012274956\n",
      "[5/5][94/100] loss: 0.012833411\n",
      "[5/5][95/100] loss: 0.012651769\n",
      "[5/5][96/100] loss: 0.012167404\n",
      "[5/5][97/100] loss: 0.012467329\n",
      "[5/5][98/100] loss: 0.012070285\n",
      "[5/5][99/100] loss: 0.011931097\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.warning('device = {}'.format(device))\n",
    "\n",
    "#     for days in [42, 90, 365]:\n",
    "    for k in range(4, 5):\n",
    "        ##### Setting Seed #####\n",
    "        seed = cfg.seed\n",
    "        seed_setting(seed)\n",
    "\n",
    "        model = convnext_tiny(len_of_clinical_features=71, use_damper=cfg.use_damper)\n",
    "        model.to(device)\n",
    "\n",
    "        weights = get_label_weights(cfg, k)\n",
    "        criterion = FocalLoss(gamma=2, weights=weights).to(device)\n",
    "        optimizer = getattr(optim, cfg.optimizer)(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        scheduler = CosineAnnealingWarmupRestarts(\n",
    "            optimizer,\n",
    "            first_cycle_steps=25,\n",
    "            cycle_mult=1.0,\n",
    "            max_lr=cfg.lr / 10,\n",
    "            min_lr=0.000001,\n",
    "            warmup_steps=10,\n",
    "            gamma=0.85,\n",
    "        )\n",
    "        # Data\n",
    "        trainset = L3_Dataset(\n",
    "            images_path=cfg.img_4c_path, \n",
    "            clinical_data_path=cfg.all_data_path,\n",
    "            train_val_test_list_path=cfg.train_val_test_list_path,\n",
    "            mode=\"train\",\n",
    "            k=k,\n",
    "#             days=days,\n",
    "            days=cfg.pred_days,\n",
    "            reverse=cfg.y_data_reverse,\n",
    "            sampling=cfg.data_sampling\n",
    "        )\n",
    "        trainloader = DataLoader(trainset, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n",
    "        valset = L3_Dataset(\n",
    "            images_path=cfg.img_4c_path, \n",
    "            clinical_data_path=cfg.all_data_path,\n",
    "            train_val_test_list_path=cfg.train_val_test_list_path,\n",
    "            mode=\"val\",\n",
    "            k=k,\n",
    "#             days=days,\n",
    "            days=cfg.pred_days,\n",
    "            reverse=cfg.y_data_reverse,\n",
    "            sampling=cfg.data_sampling\n",
    "        )\n",
    "        valloader = DataLoader(valset, batch_size=1, shuffle=False)\n",
    "\n",
    "        train(cfg, k, device, model, optimizer, criterion, scheduler, trainloader, valloader, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.get('https://hooks.zapier.com/hooks/catch/18160905/3cvu8pz/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    model = convnext_tiny(len_of_clinical_features=71, use_damper=cfg.use_damper)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('./model/auc/42d_fold2_checkpoint_epoch84.pth')['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    valset = L3_Dataset(\n",
    "        images_path=cfg.img_4c_path, \n",
    "        clinical_data_path=cfg.all_data_path,\n",
    "        train_val_test_list_path=cfg.train_val_test_list_path,\n",
    "        mode=\"val\",\n",
    "        k=2,\n",
    "        days=42,\n",
    "        reverse=cfg.y_data_reverse\n",
    "    )\n",
    "    valloader = DataLoader(valset, batch_size=1, shuffle=False)\n",
    "\n",
    "    val_label, val_pred, val_c0 = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for _, img, clinical_info, label in valloader:\n",
    "            img, clinical_info, label = img.to(device), clinical_info.to(device), label.to(device)\n",
    "            output = model(img, clinical_info)  #[bs, 2]\n",
    "\n",
    "            # _, pred = torch.max(output, dim=1)\n",
    "            c0 = output[:, 0]\n",
    "            pred = torch.where(output[:, 0] > 0.475, 0, 1)\n",
    "            val_label += label.detach().cpu().numpy().tolist()\n",
    "            val_pred += pred.detach().cpu().numpy().tolist()\n",
    "            val_c0 += c0.detach().cpu().numpy().tolist()\n",
    "\n",
    "    evaluate_preds(val_label, val_c0, val_pred)\n",
    "\n",
    "# test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4108739,
     "sourceId": 7778130,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
