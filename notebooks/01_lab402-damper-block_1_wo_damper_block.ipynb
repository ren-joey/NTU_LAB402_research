{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7755218,"sourceType":"datasetVersion","datasetId":4108739}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GPU Status","metadata":{}},{"cell_type":"code","source":"# check GPU type.\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:07.956382Z","iopub.execute_input":"2024-03-04T13:56:07.957364Z","iopub.status.idle":"2024-03-04T13:56:08.954964Z","shell.execute_reply.started":"2024-03-04T13:56:07.957322Z","shell.execute_reply":"2024-03-04T13:56:08.954054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Mon Mar  4 13:56:08 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   34C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Python package installations","metadata":{}},{"cell_type":"code","source":"!pip install torchio\n!pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:08.956816Z","iopub.execute_input":"2024-03-04T13:56:08.957104Z","iopub.status.idle":"2024-03-04T13:56:38.081436Z","shell.execute_reply.started":"2024-03-04T13:56:08.957076Z","shell.execute_reply":"2024-03-04T13:56:38.080402Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torchio\n  Downloading torchio-0.19.6-py2.py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: Deprecated in /opt/conda/lib/python3.10/site-packages (from torchio) (1.2.14)\nRequirement already satisfied: SimpleITK!=2.0.*,!=2.1.1.1 in /opt/conda/lib/python3.10/site-packages (from torchio) (2.3.1)\nRequirement already satisfied: humanize in /opt/conda/lib/python3.10/site-packages (from torchio) (4.9.0)\nRequirement already satisfied: nibabel in /opt/conda/lib/python3.10/site-packages (from torchio) (5.2.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from torchio) (1.24.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torchio) (1.11.4)\nRequirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.10/site-packages (from torchio) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchio) (4.66.1)\nRequirement already satisfied: typer[all] in /opt/conda/lib/python3.10/site-packages (from torchio) (0.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.1->torchio) (2023.12.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated->torchio) (1.14.1)\nRequirement already satisfied: packaging>=17 in /opt/conda/lib/python3.10/site-packages (from nibabel->torchio) (21.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer[all]->torchio) (8.1.7)\nRequirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]->torchio) (0.4.6)\nRequirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]->torchio) (1.5.4)\nRequirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]->torchio) (13.7.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17->nibabel->torchio) (3.1.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.1->torchio) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.1->torchio) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\nDownloading torchio-0.19.6-py2.py3-none-any.whl (173 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchio\nSuccessfully installed torchio-0.19.6\nCollecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup\n  Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to /tmp/pip-req-build-_34bihvz\n  Running command git clone --filter=blob:none --quiet https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup /tmp/pip-req-build-_34bihvz\n  Resolved https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to commit 12d03c07553aedd3d9e9155e2b3e31ce8c64081a\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: cosine_annealing_warmup\n  Building wheel for cosine_annealing_warmup (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cosine_annealing_warmup: filename=cosine_annealing_warmup-2.0-py3-none-any.whl size=4168 sha256=a4dd4ec17de65972fb29b470f00ca97a6eca9586d755fce1c26ff184c21205d3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-vkpvpj20/wheels/29/26/10/bf1a07417dd54aa73bdf09ce4f31c187974a444a1cedddbd99\nSuccessfully built cosine_annealing_warmup\nInstalling collected packages: cosine_annealing_warmup\nSuccessfully installed cosine_annealing_warmup-2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport warnings\nfrom typing import Dict\nfrom pathlib import Path\nimport pandas as pd\nimport math\n\n# System packages\nimport os\nfrom os import listdir\nfrom os.path import splitext, isfile, join\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nimport torchio as tio\n\n# Visualization packages\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import normalize\n\nfrom argparse import ArgumentParser\n\nfrom timm.models.layers import trunc_normal_\nfrom cosine_annealing_warmup import CosineAnnealingWarmupRestarts","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T13:56:38.082811Z","iopub.execute_input":"2024-03-04T13:56:38.083081Z","iopub.status.idle":"2024-03-04T13:56:47.383383Z","shell.execute_reply.started":"2024-03-04T13:56:38.083052Z","shell.execute_reply":"2024-03-04T13:56:47.382364Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class cfg:\n    seed = 77777777\n    \n    # Data\n    img_size = (512, 512)\n    in_channels = 1\n    \n    # 4 classes\n    n_classes = 4\n    train_img_path = '/kaggle/input/rtmets-sarcopenia/muscle_group_segment/train/xdata'\n    train_mask_path = '/kaggle/input/rtmets-sarcopenia/muscle_group_segment/train/ydata'\n    valid_img_path = '/kaggle/input/rtmets-sarcopenia/muscle_group_segment/validation/xdata'\n    valid_mask_path = '/kaggle/input/rtmets-sarcopenia/muscle_group_segment/validation/ydata'\n    all_img_path = '/kaggle/input/rtmets-sarcopenia/muscle_group_segment/all'\n    img_4c_path = '/kaggle/input/rtmets-sarcopenia/4_channels'\n    \n    # Clinical Data\n    train_data_path = '/kaggle/input/rtmets-sarcopenia/RT_spine_NESMS_info/train.csv'\n    valid_data_path = '/kaggle/input/rtmets-sarcopenia/RT_spine_NESMS_info/valid.csv'\n    all_data_path = '/kaggle/input/rtmets-sarcopenia/RT_spine_NESMS_info/all.csv'\n    pred_days = 42 # 42days, 90days, 365days\n    y_data_reverse = True\n    \n    # Data Folding\n    cross_valid = 1\n\n    val_percent: float = 0.1\n    img_scale: float = 1.0\n    \n    # Transforms\n    scale = (0.7, 1.0)\n    \n    # Model args\n    optimizer = 'AdamW'\n    bilinear = False\n    save_checkpoint: bool = True\n    amp: bool = False\n    checkpoint = '/kaggle/input/rtmets-sarcopenia/checkpoints/checkpoint_epoch48_0008.pth'\n    model_dir = './model'\n    \n    # Hyper parameters\n    patience: int = math.inf\n    epochs: int = 100\n    batch_size: int = 2\n    lr: float = 1e-3\n    weight_decay: float = 1e-1\n    momentum: float = 0.999\n    gradient_clipping: float = 1.0\n    optimizer = 'AdamW'\n    patience = 5\n    dropout = 0.4","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.384680Z","iopub.execute_input":"2024-03-04T13:56:47.384946Z","iopub.status.idle":"2024-03-04T13:56:47.394595Z","shell.execute_reply.started":"2024-03-04T13:56:47.384921Z","shell.execute_reply":"2024-03-04T13:56:47.393607Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def seed_setting(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.enabled = False\n\ndef save_model(model_dir, model, args, epoch=None):\n    model_dir = Path(model_dir)\n    model_dir.mkdir(parents=True, exist_ok=True)\n\n    torch.save({\n        'epochs': args.epochs,\n        'model_state_dict': model.state_dict(),\n        'batch_size': args.batch_size,\n        'lr': args.lr,\n        'weight_decay': args.weight_decay,\n        'optimizer': args.optimizer,\n        'patience': args.patience,\n    }, str(model_dir) + 'checkpoint_epoch{}.pth'.format(epoch))\n\ndef get_label_weights(args, k):\n    weights = [3, 1]\n    print('weights = ', weights)\n    weights = torch.tensor(weights.copy(), dtype=torch.float32)\n    weights = weights.to(device)\n    return weights\n\n# all_scorer = sklearn.metrics.get_scorer_names()\n# print(all_scorer)\n\ndef evaluate_preds(y_test, preds, threshold=0.5):    \n    _preds = []\n    for i, v in enumerate(preds):\n        _preds.append(1 if (v > threshold) else 0)\n\n    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, _preds).ravel()\n    print(tn, fp, fn, tp)\n\n    acc = (tp+tn)/(tn+fp+fn+tp)\n    # acc = sklearn.metrics.accuracy_score(y_test, _preds)\n\n    sensitivity = tp/(tp+fn) # Recall\n    # sensitivity = sklearn.metrics.recall_score(y_test, _preds)\n\n    precision = tp/(tp+fp) # Precision & ppv\n    # precision = sklearn.metrics.precision_score(y_test, _preds)\n\n    npv = tn/(tn+fn)\n\n    specificity = tn/(tn+fp)\n\n    try:\n        f1 = ((2*precision*sensitivity)/(precision+sensitivity))\n    except:\n        f1 = 0\n    # f1 = sklearn.metrics.f1_score(y_test, _preds)\n\n    auc = sklearn.metrics.roc_auc_score(y_test, preds)\n\n    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, preds)\n#     print(fpr)\n#     print(tpr)\n#     print(thresholds)\n    roc_auc = sklearn.metrics.auc(fpr, tpr)\n    display = sklearn.metrics.RocCurveDisplay(\n        fpr=fpr,\n        tpr=tpr,\n        roc_auc=roc_auc\n    )\n    display.plot()\n    plt.show()\n\n#     print(f'model_name: {cfg.model_name}')\n    print(f'acc: {acc}\\nsensitivity: {sensitivity}\\nspecificity: {specificity}\\nppv(precision): {precision}\\nnpv: {npv}\\nF1-score: {f1}\\nAUC: {auc}')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.397322Z","iopub.execute_input":"2024-03-04T13:56:47.397695Z","iopub.status.idle":"2024-03-04T13:56:47.416637Z","shell.execute_reply.started":"2024-03-04T13:56:47.397664Z","shell.execute_reply":"2024-03-04T13:56:47.415517Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparing","metadata":{}},{"cell_type":"code","source":"def data_preparing(data_path):\n    res = pd.read_csv(data_path)\n    data = res.values\n    header = res.columns.to_numpy()\n    \n    x_data, y_42d_data, y_90d_data, y_365d_data = data[:, :-3], data[:, -3], data[:, -2], data[:, -1]\n    \n    return x_data, y_42d_data, y_90d_data, y_365d_data, header","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.417638Z","iopub.execute_input":"2024-03-04T13:56:47.417892Z","iopub.status.idle":"2024-03-04T13:56:47.434280Z","shell.execute_reply.started":"2024-03-04T13:56:47.417870Z","shell.execute_reply":"2024-03-04T13:56:47.433429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Datasets","metadata":{}},{"cell_type":"code","source":"os.environ['KMP_DUPLICATE_LIB_OK']='True'\nos.environ['CUDA_LAUNCH_BLOCKING']='1'\n\n##### Dataset #####\nclass L3_Dataset(Dataset):\n    def __init__(self, images_path=None, clinical_data_path=None, train_val_test_list_path=None, mode=None, k=0, predict_mode=False, days=42):\n        self.images_path = images_path\n        self.clinical_data_path = clinical_data_path\n        self.mode = mode\n        self.predict_mode = predict_mode  \n        \n        self.x_data, y_42d_data, y_90d_data, y_365d_data, self.header = data_preparing(self.clinical_data_path)\n        if days == 42:\n            self.y_data = y_42d_data\n        elif days == 90:\n            self.y_data = y_90d_data\n        elif days == 365:\n            self.y_data = y_365d_data\n        \n    def __len__(self):\n        return len(self.x_data)\n\n    def __getitem__(self, idx):\n        img_path = Path(self.images_path, f'{idx+1}.npy')\n#         mask_path = Path(self.images_path, 'ydata', f'{idx+1}.png')\n        img_name = img_path.stem\n\n        # label\n        label = self.y_data[idx]\n        label = int(label)\n        label = torch.tensor(label)\n\n        # Image\n        c4_img = np.load(img_path)\n        c4_img = c4_img.astype(np.float32)\n#         c4_img = np.zeros((512, 512, 4), dtype=np.float32)\n#         ct_img = np.array(Image.open(img_path))\n#         mask_img = np.array(Image.open(mask_path))\n#         for (y, rows) in enumerate(ct_img):\n#             for (x, p) in enumerate(rows):\n#                 [r, g, b] = mask_img[y][x]\n#                 c4_img[y][x] = [r, g, b, p]\n        c4_img = c4_img[:, :, :, np.newaxis].transpose((2, 3, 0, 1))\n\n        # clinical features\n        clinical_values = torch.tensor(self.x_data[idx], dtype=torch.float32)\n\n        return img_name, c4_img, clinical_values, label","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.435517Z","iopub.execute_input":"2024-03-04T13:56:47.436259Z","iopub.status.idle":"2024-03-04T13:56:47.450230Z","shell.execute_reply.started":"2024-03-04T13:56:47.436227Z","shell.execute_reply":"2024-03-04T13:56:47.449450Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=0, size_average=True, weights=None):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.size_average = size_average\n        self.weights = weights\n\n    def forward(self, input, target):\n        pt = F.softmax(input, dim=1)\n        logpt = F.log_softmax(input, dim=1)\n        weights = self.weights.index_select(0, target) # nice\n        target = target.view(-1, 1) # 1維 -> 2維\n\n        pt = pt.gather(1, target)\n        logpt = logpt.gather(1, target)\n        pt = pt.view(-1)\n        logpt = logpt.view(-1)\n\n        loss = -1 * weights * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.451404Z","iopub.execute_input":"2024-03-04T13:56:47.452031Z","iopub.status.idle":"2024-03-04T13:56:47.464546Z","shell.execute_reply.started":"2024-03-04T13:56:47.451998Z","shell.execute_reply":"2024-03-04T13:56:47.463691Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Blocks","metadata":{}},{"cell_type":"code","source":"class SE(nn.Module):\n    def __init__(self, channel, reduction=2):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1, 1)\n        return x * y.expand_as(x)\n\nclass GCT(nn.Module):\n    def __init__(self, channel, epsilon=1e-5, mode='l2', after_relu=False):\n        super(GCT, self).__init__()\n        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.epsilon = epsilon\n        self.mode = mode\n        self.after_relu = after_relu\n\n    def forward(self, x):\n        if self.mode == 'l2':\n            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n        else:\n            print('Unknown mode!')\n            sys.exit()\n\n        # gate = 1. + torch.tanh(embedding * norm + self.beta)\n        gate = 1. + torch.sigmoid(embedding * norm + self.beta)\n\n        return x * gate\n\nclass BAM(nn.Module):\n    def __init__(self, gate_channel, reduction=2, dilation_val=4, num_layers=1):\n        super(BAM, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        self.channel_att = nn.Sequential(\n            nn.Linear(gate_channel, gate_channel // reduction),\n            nn.ReLU(),\n            nn.Linear(gate_channel // reduction, gate_channel)\n        )\n\n        # input (_, _, D, H, W) -> output (_, _, D, H, W) for any Conv3D\n        self.spatial_att = nn.Sequential(\n            nn.Conv3d(gate_channel, gate_channel // reduction, kernel_size=1),\n            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(gate_channel // reduction, gate_channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(gate_channel // reduction, gate_channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n            LayerNorm(gate_channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(gate_channel//reduction, 1, kernel_size=1)\n        )\n\n    def forward(self, x):\n        b, c, _, _, _ = x.size()\n        # compute channel attention\n        channel_part = self.avg_pool(x).view(b, c)\n        channel_part = self.channel_att(channel_part).view(b, c, 1, 1, 1).expand_as(x)\n        # compute spatial attention\n        spatial_part = self.spatial_att(x).expand_as(x)\n        # add together\n        att = 1 + F.sigmoid(channel_part + spatial_part)\n        return att * x\n\nclass CBAM(nn.Module):\n    def __init__(self, gate_channel, reduction=2):\n        super().__init__()\n        # channel attention\n        self.pools = [\n            nn.AdaptiveAvgPool3d(1),\n            nn.AdaptiveMaxPool3d(1)\n        ]\n        self.mlp = nn.Sequential(\n            nn.Linear(gate_channel, gate_channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(gate_channel // reduction, gate_channel)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n        # spatial attention\n        kernel_size = 7\n        self.conv = nn.Sequential(\n            nn.Conv3d(2, 1, kernel_size=kernel_size, stride=1, padding=(kernel_size-1) // 2),\n            LayerNorm(1, data_format=\"channels_first\"),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        res = x\n        b, c, _, _, _ = x.size()\n\n        channel_part = None\n        for pool in self.pools:\n            y = pool(x).view(b, c)\n            y = self.mlp(y)\n            channel_part = channel_part + y if channel_part is not None else y \n        channel_part = self.sigmoid(channel_part).view(b, c, 1, 1, 1)\n        x = x * channel_part.expand_as(x)\n\n        spatial_part = torch.cat( (torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1 )\n        spatial_part = self.conv(spatial_part)\n        x = x * spatial_part.expand_as(x)\n\n        return x + res\n\nclass SE_GCT(nn.Module):\n    def __init__(self, channel, reduction=2, epsilon=1e-5, mode='l2', after_relu=False):\n        super().__init__()\n        # Squeeze and excitation\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel),\n        )\n        # GCT\n        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.epsilon = epsilon\n        self.mode = mode\n        self.after_relu = after_relu\n\n    def forward(self, x):\n        # compute SE attention\n        b, c, _, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        se_gate = self.fc(y).view(b, c, 1, 1, 1).expand_as(x)\n\n        # compute GCT attention\n        if self.mode == 'l2':\n            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n        else:\n            print('Unknown mode!')\n            sys.exit()\n        gct_gate = embedding * norm + self.beta\n\n        # add together\n        att = 1 + F.sigmoid(se_gate + gct_gate)\n        return att * x\n\nclass BAM_GCT(nn.Module):\n    def __init__(self, channel, reduction=2, dilation_val=4, num_layers=1, epsilon=1e-5, mode='l2', after_relu=False):\n        super().__init__()\n        # Squeeze and excitation\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel),\n        )\n        # GCT\n        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.epsilon = epsilon\n        self.mode = mode\n        self.after_relu = after_relu\n\n        # input (_, _, D, H, W) -> output (_, _, D, H, W) for any Conv3D\n        self.spatial_att = nn.Sequential(\n            nn.Conv3d(channel, channel // reduction, kernel_size=1),\n            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(channel // reduction, channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(channel // reduction, channel // reduction, kernel_size=3, padding=dilation_val, dilation=dilation_val),\n            LayerNorm(channel // reduction, data_format=\"channels_first\"),\n            nn.GELU(),\n            nn.Conv3d(channel//reduction, 1, kernel_size=1)\n        )\n\n    def forward(self, x):\n        b, c, _, _, _ = x.size()\n        # compute channel attention\n\n        # compute SE attention\n        b, c, _, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1, 1).expand_as(x)\n\n        # compute GCT attention\n        if self.mode == 'l2':\n            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n        else:\n            print('Unknown mode!')\n            sys.exit()\n        gate = embedding * norm + self.beta\n\n        # add together\n        channel_part = y + gate\n\n        # compute spatial attention\n        spatial_part = self.spatial_att(x).expand_as(x)\n        # add together\n        att = 1 + F.sigmoid(channel_part + spatial_part)\n        return att * x\n\nclass CBAM_GCT(nn.Module):\n    def __init__(self, channel, reduction=2, epsilon=1e-5, mode='l2', after_relu=False):\n        super().__init__()\n        # channel attention\n        self.pools = [\n            nn.AdaptiveAvgPool3d(1),\n            nn.AdaptiveMaxPool3d(1)\n        ]\n        self.mlp = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n        # GCT\n        self.alpha = nn.Parameter(torch.ones(1, channel, 1, 1, 1))\n        self.gamma = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.beta = nn.Parameter(torch.zeros(1, channel, 1, 1, 1))\n        self.epsilon = epsilon\n        self.mode = mode\n        self.after_relu = after_relu\n\n        # spatial attention\n        kernel_size = 7\n        self.conv = nn.Sequential(\n            nn.Conv3d(2, 1, kernel_size=kernel_size, stride=1, padding=(kernel_size-1) // 2),\n            LayerNorm(1, data_format=\"channels_first\"),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        res = x\n        b, c, _, _, _ = x.size()\n\n        channel_part = None\n        for pool in self.pools:\n            y = pool(x).view(b, c)\n            y = self.mlp(y)\n            channel_part = channel_part + y if channel_part is not None else y \n        channel_part = channel_part.view(b, c, 1, 1, 1)\n\n        # compute GCT attention\n        if self.mode == 'l2':\n            embedding = (x.pow(2).sum((2, 3, 4), keepdim=True) + self.epsilon).pow(0.5) * self.alpha\n            norm = self.gamma / (embedding.pow(2).mean(dim=1, keepdim=True) + self.epsilon).pow(0.5)\n        else:\n            print('Unknown mode!')\n            sys.exit()\n        gate = embedding * norm + self.beta\n\n        # add together\n        channel_part = channel_part + gate\n        channel_part = F.sigmoid(channel_part)\n        x = x * channel_part.expand_as(x)\n\n        spatial_part = torch.cat( (torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1 )\n        spatial_part = self.conv(spatial_part)\n        x = x * spatial_part.expand_as(x)\n\n        return x + res\n\nclass LayerNorm(nn.Module):\n    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n    with shape (batch_size, channels, height, width).\n    \"\"\"\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError\n        self.normalized_shape = (normalized_shape, )\n    \n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n            return x","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.467269Z","iopub.execute_input":"2024-03-04T13:56:47.467541Z","iopub.status.idle":"2024-03-04T13:56:47.526507Z","shell.execute_reply.started":"2024-03-04T13:56:47.467518Z","shell.execute_reply":"2024-03-04T13:56:47.525391Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"class GRN(nn.Module):\n    # gamma, beta: learnable affine transform parameters\n    # X: input of shape (N, D, H, W, C)\n    def __init__(self, dim):\n        super().__init__()\n        self.gamma = nn.Parameter(torch.zeros((dim)))\n        self.beta = nn.Parameter(torch.zeros((dim)))\n\n    def forward(self, x):\n        gx = torch.norm(x, p=2, dim=(1, 2, 3), keepdim=True)\n        nx = gx / (gx.mean(dim=-1, keepdim=True) + 1e-6)\n        return self.gamma * (x * nx) + self.beta + x\n\nclass Block(nn.Module):\n    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n    (2) DwConv -> Permute to (N, D, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n    We use (2) as we find it slightly faster in PyTorch\n    \n    Args:\n        dim (int): Number of input channels.\n        drop_path (float): Stochastic depth rate. Default: 0.0\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n    \"\"\"\n    def __init__(self, dim, depth_number: int, pos_in_depth: int, drop_path=0.5, layer_scale_init_value=1e-6):\n        super().__init__()\n        self.dwconv = nn.Conv3d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n        self.act = nn.GELU()\n        self.pwconv2 = nn.Linear(4 * dim, dim)\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n                                    requires_grad=True) if layer_scale_init_value > 0 else None\n        self.depth_number = depth_number\n        self.pos_in_depth = pos_in_depth\n        self.se_gct = SE_GCT(channel=dim, reduction=2)\n        self.dim = dim\n\n    def forward(self, x):\n        input = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 4, 1) # (N, C, D, H, W) -> (N, D, H, W, C)\n        x = self.norm(x)\n        x = self.pwconv1(x)\n        x = self.act(x)\n        x = self.pwconv2(x)\n        if self.gamma is not None:\n            x = self.gamma * x\n        x = x.permute(0, 4, 1, 2, 3) # (N, D, H, W, C) -> (N, C, D, H, W)\n\n        if self.pos_in_depth == 3:\n            x = self.se_gct(x)\n\n        x = input + x\n        return x\n\nclass ConvNeXt(nn.Module):\n    r\"\"\" ConvNeXt\n        A PyTorch impl of : `A ConvNet for the 2020s`  -\n          https://arxiv.org/pdf/2201.03545.pdf\n\n    Args:\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n        drop_path_rate (float): Stochastic depth rate. Default: 0.\n        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n    \"\"\"\n    def __init__(\n            self, in_chans=4, num_classes=2, \n            depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n            layer_scale_init_value=1e-6, head_init_scale=1., len_of_clinical_features=71\n        ):\n        super().__init__()\n\n        # depths=[1, 1, 3, 1], dims=[8, 16, 32, 64]\n        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n        stem = nn.Sequential(\n            nn.Conv3d(in_chans, dims[0], kernel_size=(1, 4, 4), stride=4),\n            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n        )\n        self.downsample_layers.append(stem)\n        for i in range(3):\n            downsample_layer = nn.Sequential(\n                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n                nn.Conv3d(dims[i], dims[i+1], kernel_size=(1, 2, 2), stride=2),\n            )\n            self.downsample_layers.append(downsample_layer)\n\n        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n        cur = 0\n        for i in range(4):\n            stage = nn.Sequential(\n                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], layer_scale_init_value=layer_scale_init_value, depth_number=i+1, pos_in_depth=j+1) for j in range(depths[i])]\n            )\n            self.stages.append(stage)\n            cur += depths[i]\n\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n\n        # voi size\n#         self.v_fc1 = nn.Linear(3, 16)\n#         self.v_fc2 = nn.Linear(16, dims[-1])\n#         self.v_fc3 = nn.Linear(dims[-1], dims[-1])\n\n        # final\n        len_of_features = dims[-1] + len_of_clinical_features\n        self.fc1 = nn.Linear(len_of_features, len_of_features // 2) # 214 = dim[-1] + dim(clinical_info) which is 150\n        self.fc2 = nn.Linear(len_of_features // 2, 2)\n        self.bn1 = nn.BatchNorm1d(len_of_features // 2)\n        self.softmax = nn.Softmax(dim=1)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, (nn.Conv3d, nn.Linear)):\n            trunc_normal_(m.weight, std=.02) # 正態分佈\n            nn.init.constant_(m.bias, 0)\n\n    def forward_features(self, x):\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.stages[i](x)\n        return self.norm(x.mean([-3, -2, -1])) # global average pooling, (N, C, D, H, W) -> (N, C)\n\n    def forward(self, x, clinical_info):\n        x_feature = self.forward_features(x)\n#         voi_feature = self.v_fc1(voi_size)\n#         voi_feature = self.v_fc2(voi_feature)\n#         voi_feature = self.v_fc3(voi_feature)\n\n#         b, n = x_feature.size()\n#         _sum = (x_feature * voi_feature).sum(dim=(-1))\n#         x = x_feature - (_sum / n).view(b, 1).expand_as(x_feature)\n\n        x = torch.cat((x_feature, clinical_info), 1)\n        x = F.leaky_relu(self.bn1(self.fc1(x)))\n        x = self.fc2(x)\n        x = self.softmax(x)\n\n        return x\n\ndef convnext_tiny(pretrained=False, in_22k=False, **kwargs):\n    # original dims = [96, 192, 384, 768]\n    # best dims = [8, 16, 32, 64]\n    model = ConvNeXt(depths=[1, 1, 3, 1], dims=[8, 16, 32, 64], **kwargs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.527921Z","iopub.execute_input":"2024-03-04T13:56:47.528837Z","iopub.status.idle":"2024-03-04T13:56:47.556506Z","shell.execute_reply.started":"2024-03-04T13:56:47.528808Z","shell.execute_reply":"2024-03-04T13:56:47.555776Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Training Functions","metadata":{}},{"cell_type":"code","source":"def train(args, k: int, device, model, optimizer, criterion, scheduler, trainloader, valloader, seed):\n    \n    the_last_loss = 100\n    trigger_times = 0\n\n    the_best_loss = 0\n    the_best_accuracy = 0\n\n    save_path = Path(args.model_dir)\n    save_tradoff_path = Path(args.model_dir, 'tradoff')\n\n    for epoch in range(args.epochs):\n        epoch_loss, epoch_accuracy = 0, 0\n        train_label, train_pred = [], []\n        model.train()\n        for i, (_, img, clinical_info, label) in enumerate(trainloader):\n            img, clinical_info, label = img.to(device), clinical_info.to(device), label.to(device)\n\n            output = model(img, clinical_info)  #[bs, 2]\n\n            torch.cuda.empty_cache()\n\n            # _, pred = torch.max(output, dim=1)\n            pred = torch.where(output[:, 0] > 0.475, 0, 1)\n            # TODO: 不確定 label 有沒有二極化\n            loss = criterion(output, label)  #focal\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.detach().cpu().item()\n            epoch_accuracy += torch.sum(pred == label)\n\n            train_label += label.detach().cpu().numpy().tolist()\n            train_pred += pred.detach().cpu().numpy().tolist()\n\n        scheduler.step()\n\n        epoch_loss = epoch_loss / (len(trainloader) * args.batch_size)\n        epoch_accuracy = epoch_accuracy.float() / (len(trainloader) * args.batch_size)\n        tp, fn, fp, tn = confusion_matrix(train_label, train_pred).ravel()\n        tnr, fpr, fnr, tpr = tn/(fp+tn), fp/(fp+tn), fn/(tp+fn), tp/(tp+fn)\n        print(f'[{k}/{5}][{epoch}/{args.epochs}] loss: {epoch_loss:.8}, accuracy: {epoch_accuracy:.2}, tnr = {tnr:.2}, tpr = {tpr:.2}')\n\n        # Early stopping\n        the_current_loss, the_current_accuracy, the_current_tnr, the_current_tpr = validation(device, model, criterion, valloader)\n        print(f'[validation] The current loss: {the_current_loss:.8}, accuracy: {the_current_accuracy:.2}, tnr = {the_current_tnr:.2}, tpr = {the_current_tpr:.2}')\n\n        if the_current_loss > the_last_loss:\n            trigger_times += 1\n            print('trigger times:', trigger_times)\n\n            if trigger_times >= args.patience:\n                print(f'Early stopping!\\nEpoch = {epoch}')\n                return\n        else:\n            print('trigger times: 0')\n            trigger_times = 0\n\n        if epoch == 0 or the_best_loss >= the_current_loss:\n            print(f'Recording best model. ({save_path})')\n            save_model(save_path, model, args, epoch)\n            the_best_loss = the_current_loss\n\n        if epoch == 0 or (the_best_accuracy <= the_current_accuracy and abs(the_current_tnr-the_current_tpr) <= 0.15):\n            print(f'Recording best tradeoff model. ({save_tradoff_path})')\n            save_model(save_tradoff_path, model, args, epoch)\n            the_best_accuracy = the_current_accuracy\n\n        the_last_loss = the_current_loss\n\n    print(f'stopping! Epoch = {args.epochs}')\n    return \n\ndef validation(device, model, criterion, valloader):\n    model.eval()\n    val_loss = 0\n    val_accuracy = 0\n    val_label, val_pred, val_c0 = [], [], []\n\n    with torch.no_grad():\n        for _, img, clinical_info, label in valloader:\n            img, clinical_info, label = img.to(device), clinical_info.to(device), label.to(device)\n            output = model(img, clinical_info)  #[bs, 2]\n            \n            # _, pred = torch.max(output, dim=1)\n            c0 = output[:, 0]\n            pred = torch.where(output[:, 0] > 0.475, 0, 1)\n            loss = criterion(output, label)  #focal\n            val_loss += loss.detach().cpu().item()\n            val_accuracy += torch.sum(pred == label)\n\n            val_label += label.detach().cpu().numpy().tolist()\n            val_pred += pred.detach().cpu().numpy().tolist()\n            val_c0 += c0.detach().cpu().numpy().tolist()\n\n    evaluate_preds(val_label, val_c0, 0.5)\n\n    val_loss = val_loss / len(valloader)\n    val_accuracy = val_accuracy.float() / len(valloader)\n    tp, fn, fp, tn = confusion_matrix(val_label, val_pred).ravel()\n    tnr, fpr, fnr, tpr = tn/(fp+tn), fp/(fp+tn), fn/(tp+fn), tp/(tp+fn)\n            \n    return val_loss, val_accuracy, tnr, tpr","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.557878Z","iopub.execute_input":"2024-03-04T13:56:47.558171Z","iopub.status.idle":"2024-03-04T13:56:47.580818Z","shell.execute_reply.started":"2024-03-04T13:56:47.558136Z","shell.execute_reply":"2024-03-04T13:56:47.579936Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Arguments Preparing","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start Training","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__' :\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"device = \", device)\n\n    for k in range(1, 6):\n        ##### Setting Seed #####\n        seed = cfg.seed\n        seed_setting(seed)\n\n        model = convnext_tiny(len_of_clinical_features=71)\n        model.to(device)\n\n        weights = get_label_weights(cfg, k)\n        criterion = FocalLoss(gamma=2, weights=weights).to(device)\n        optimizer = getattr(optim, cfg.optimizer)(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n\n        scheduler = CosineAnnealingWarmupRestarts(\n            optimizer,\n            first_cycle_steps=20,\n            cycle_mult=1.0,\n            max_lr=cfg.lr,\n            min_lr=0.000001,\n            warmup_steps=10,\n            gamma=1.0,\n        )\n        # Data\n        trainset = L3_Dataset(\n            images_path=cfg.img_4c_path, \n            clinical_data_path=cfg.all_data_path,\n            mode=\"train\",\n            k=k,\n            days=cfg.pred_days\n        )\n        trainloader = DataLoader(trainset, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n        valset = L3_Dataset(\n            images_path=cfg.img_4c_path, \n            clinical_data_path=cfg.all_data_path,\n            mode=\"val\",\n            k=k,\n            days=cfg.pred_days\n        ) \n        valloader = DataLoader(valset, batch_size=1, shuffle=False)\n        \n        train(cfg, k, device, model, optimizer, criterion, scheduler, trainloader, valloader, seed)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T13:56:47.581840Z","iopub.execute_input":"2024-03-04T13:56:47.582127Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"device =  cuda\nweights =  [3, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}